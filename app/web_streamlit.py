import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel


BASE_MODEL = "Qwen/Qwen2.5-0.5B"        # å’Œä½ è®­ç»ƒæ—¶ä¸€è‡´
LORA_PATH = "./output/checkpoint-final" # ä½ çš„ LoRA è·¯å¾„ï¼ˆæŒ‰ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ï¼‰


# --------------------------
# å¼ºåˆ¶ä½¿ç”¨ slow tokenizerï¼ˆå…¼å®¹æ—§æ¨¡å‹ï¼‰
# --------------------------
def load_tokenizer(model_name):
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        use_fast=False,   # ğŸ”¥ ç¦ç”¨ fast tokenizer
        trust_remote_code=True
    )
    return tokenizer


# --------------------------
# å…¼å®¹æ—§ç‰ˆ Qwen2 + LoRA çš„æ¨¡å‹åŠ è½½
# --------------------------
def load_model():
    base = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL,
        torch_dtype=torch.float16,
        device_map="auto",
        trust_remote_code=True
    )

    # åŠ è½½ LoRAï¼Œå…¼å®¹æ—§ peft==0.4 - 0.6
    model = PeftModel.from_pretrained(
        base,
        LORA_PATH,
        torch_dtype=torch.float16,
    ).eval()

    return model


# --------------------------
# Streamlit APP
# --------------------------
st.title("ç»¿è‰²å»ºç­‘é—®ç­”æœºå™¨äººï¼ˆStreamlit | æ—§æ¨¡å‹å…¼å®¹ç‰ˆï¼‰")

@st.cache_resource
def load_all():
    tok = load_tokenizer(BASE_MODEL)
    model = load_model()
    return tok, model


with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹...ï¼ˆé¦–æ¬¡åŠ è½½éœ€è¦ 20 ç§’å·¦å³ï¼‰"):
    tokenizer, model = load_all()


# --------------------------
# èŠå¤©é€»è¾‘
# --------------------------
def chat(query):
    inputs = tokenizer(query, return_tensors="pt").to(model.device)
    with torch.no_grad():
        output = model.generate(
            **inputs,
            max_new_tokens=200,
            do_sample=True,
            temperature=0.6,
            top_p=0.9
        )
    return tokenizer.decode(output[0], skip_special_tokens=True)


# --------------------------
# UI
# --------------------------
user_input = st.text_area("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š")

if st.button("å‘é€"):
    if user_input.strip():
        with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
            answer = chat(user_input)
        st.success(answer)


